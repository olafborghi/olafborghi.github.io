---
title: "Teaching Myself: Bayesian Multiple and Multivariate Linear Regression"
author: "Olaf Borghi"
date: 2024-03-30
description: "In the last week, I ran a Bayesian Linear Regression with a single predictor and outcome variable. Usually, we investigate the effects of multiple predictors or control for confounding variables when the goal is to make an inference about and not to merely describe a relationship. In many cases, we also have more than one outcome variable. So let's take the next step and run a multiple linear and a multivariate regression in brms!"
categories:
  - r
  - Bayes
  - Regression
  - Multiple regression
freeze: true
format:
  html:
    toc-depth: 4
embed-resources: true
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
# knit settings
knitr::opts_chunk$set(fig.align = "center", fig.retina = 3,
                      fig.width = 6, fig.height = (6 * 0.618),
                      out.width = "90%", collapse = TRUE)
options(digits = 3, width = 90)

# set error messages to English
Sys.setenv(LANG = "en")

# Make all the random draws reproducible
set.seed(42)
```

```{r libraries, warning=FALSE, message=FALSE}
# use groundhog to make code maximally reproducible
if (!require("groundhog", quietly = TRUE)) {
  install.packages("groundhog")
}
library("groundhog")

# use groundhog to install and load packages - we may not use all of them and some consider it bad practise
# to still load them, but all of them are nice to have and could be useful
pkgs <- c("here",         # Path management
          "tidyverse",    # ggplot, dplyr, %>%, and friends
          "easystats",    # bayestestR, performance, effectsize and friends
          "psych",        # Descriptive statistics and other tools
          "brms",         # Bayesian modeling through Stan
          "tidybayes",    # Integration of Bayesian models in tidy + ggplot workflow
          "broom",        # Convert model objects to data frames
          "broom.mixed",  # Convert brms model objects to data frames
          "marginaleffects", # Compute marginal effects
          "tinytable",    # Lightweight package to create tables
          "hrbrthemes",   # Additional ggplot themes
          "extrafont",    # Additional fonts for plots etc
          "ggdist",       # Special geoms for posterior distributions
          "ggrepel",      # Automatically position labels
          "gghalves",     # Special half geoms
          "patchwork"     # Combine ggplot objects
          )

groundhog.library(pkgs, "2024-03-01") # change to a recent date
```

```{r load-fonts, include=FALSE}
loadfonts(quiet = TRUE)
```

```{r Stan backend, include=FALSE}
# you may also use the faster cmdstanr backend for Stan in the place of rstan
# Yto do so install the cmdstanr package first: https://mc-stan.org/cmdstanr/
# Then run cmdstanr::install_cmdstan() to install cmdstan on your computer.

options(mc.cores = 4,  # Use 4 cores
        brms.backend = "rstan")
bayes_seed <- 42
```

## Teaching Myself: Bayesian Multiple Linear Regression

This blog article builds on the analyses from the last blog post on Bayesian linear regression. We will use part of the same data, but this time investigate the effects of multiple predictor variables simultaneously. You may have noticed how we plotted the association of self-reported and behavioral self-control with authoritarianism, but in our regression only included self-reported self-control as a predictor. So let's go one step further!

### Meet the data

This time, I only use open data from [Zmigrod et al. (2021)](https://zenodo.org/records/4434725/files/Data%20-%20Zmigrod%20et%20al%202021%20Philosophical%20Transactions.xlsx?download=1). This dataset includes cognitive and personality factors derived from exploratory factor analysis (EFA) of a large number of behavioral cognitive tasks and personality questionnaires from the Self-Regulation Ontology, and in addition to that, several measures of ideology.

Zmigrod et al. (2021) use EFA to obtain three factors of ideology. I can highly suggest to read the article, both the analytic approach and the results are very interesting - [You can find it here](https://royalsocietypublishing.org/doi/10.1098/rstb.2020.0424).

In this blog post I will skip the factor analysis of the ideology measures, and directly investigate the relative associations of the cognitive factors with self-reported measures of ideology, thus taking a bit of a different analytic approach.

```{r Load data, include=FALSE}
data_path <- here("01_data", "ideology_data.csv")

data <- read_csv(data_path)
```

We will investigate the associations of five cognitive factors

-   Caution, Temporal Discounting, Perceptual Processing Time, Speed of Evidence Accumulation, and Strategic Information Processing

With the score on three ideology questionnaires that measure

-   Conservatism, Authoritarianism, and Dogmatism

And we will control for the demographic variables

-   Gender, Age, Education and Income

Let's select the data that we are interested in here.

```{r data descriptives}
# select variables of interest
dat <- data %>%
  select(1, 3:11, 24, 32, 33) %>%
  rename(ID = SubjectN) 

str(dat)
```

I want to standardize the variables again. However, as we have categorical and binary predictors, to be able to compare the sizes of effects, this time we standardize all continuous variables by 2 SD. This puts them on a scale that is comparable with binary or dummy-coded predictors.

For more information on this procedure, please see these articles / blog posts by Andrew Gelman

<https://statmodeling.stat.columbia.edu/2009/07/11/when_to_standar/>

<http://www.stat.columbia.edu/~gelman/research/published/standardizing7.pdf>

Let's first change the data type of Gender.

```{r as-factor}

d <- dat %>% 
  mutate(Gender = as.factor(Gender))

str(d)
```

Alright, now let's scale the continuous predictor variables to have a mean of 0 and a sd of 0.5 and the continuous outcome variables to have a mean of 0 and a SD of 1.

```{r scale2sd-variables}

d <- d %>% 
  mutate(across(c(SpeededIP, StrategicIP, Percep, Caution, Discount, Age, Edu, Income), 
                ~ (.x - mean(.x, na.rm = TRUE)) / (2 * sd(.x, na.rm = TRUE))),
         across(c(Conservatism, Authoritarianism, Dogmatism), scale))


d_des <- describe(d)
d_des %>% 
  select(mean, sd)
```

As I am curious, I create a second dataframe in which I use the more common approach to scale continuous predictor and outcome variables to have a mean of 0 and a sd of 1. To make effects comparable to a binary predictor, we use effect coding for the variable `gender` (see <https://statmodeling.stat.columbia.edu/2009/06/09/standardization/>)

```{r scale1sd-variables}

d1sd <- d %>% 
  mutate(across(where(is.numeric), scale))

contrasts(d1sd$Gender) <- contr.sum(levels(d1sd$Gender))

d1sd_des <- describe(d1sd) 
d1sd_des %>% 
  select(mean, sd)
```

I am very curious. Technically, not only `gender`, but also `education` is a categorical variable, and I want to treat it as such. Let's look at how many numbers of observation we have for each level of education.

Some factor levels have very few observations that do not all for comparisons. So let's collapse them into a few, less levels.

```{r recode-education}
df <- dat %>%
  mutate(EduFactor = case_when(
    Edu %in% c(1, 2) ~ "High school (and lower)",
    Edu %in% c(3, 4) ~ "Below Bachelor",
    Edu %in% c(5, 6, 7) ~ "Bachelor, Master, Doctorate",
    TRUE ~ NA_character_  # This line is optional, handles unexpected cases
  ))  %>%
  mutate(EduFactor = factor(EduFactor, levels = c("High school (and lower)", "Below Bachelor", "Bachelor, Master, Doctorate")),
          Gender = as.factor(Gender)) %>% 
  mutate(across(where(is.numeric), scale))
```

To make the effects of different input variables comparable, let's standardize numerical variables and use effect coding for categorical variables again.

```{r effect-coding-edu}

# Gender
contrasts(df$Gender) <- contr.sum(levels(df$Gender))
contrasts(df$Gender)

# Education
# Define the contrast matrix
contrast_edu <- matrix(c(1, -1, -1,
                        -1,  1, -1,
                        -1, -1, -1),
                      byrow = TRUE,  
                      ncol = 3)      
contrasts(df$EduFactor) <- contrast_edu
contrasts(df$EduFactor)
```

This coding ensures that each level's effects are considered relative to the overall mean (similar to traditional effect coding), but with adjustments to balance the variance attributed to each level in the prior predictive distribution, by replacing 0s with -1s. I am not an expert on this so please see this for some literature on why this should work:\
<https://discourse.mc-stan.org/t/symmetric-weakly-informative-priors-for-categorical-predictors/22188/5>

Create yet another dataframe in which I use usual dummy-coding

```{r}
df_dummy <- dat %>%
  mutate(EduFactor = case_when(
    Edu %in% c(1, 2) ~ "High school (and lower)",
    Edu %in% c(3, 4) ~ "Below Bachelor",
    Edu %in% c(5, 6, 7) ~ "Bachelor, Master, Doctorate",
    TRUE ~ NA_character_  # This line is optional, handles unexpected cases
  ))  %>%
  mutate(EduFactor = factor(EduFactor, levels = c("High school (and lower)", "Below Bachelor", "Bachelor, Master, Doctorate")),
          Gender = as.factor(Gender)) %>% 
  mutate(across(where(is.numeric), scale))
```

Let's plot the distributions of our outcome variables next.

```{r outcome-variables-densityplots, message=FALSE, warning=FALSE}

vars1_density<- df %>%
  select(c(Conservatism, Authoritarianism, Dogmatism)) %>%
  pivot_longer(., cols = c(Conservatism, Authoritarianism, Dogmatism), 
               names_to = "Variable", values_to = "Value") %>%
  ggplot(aes(x = Value, fill = factor(Variable))) + 
  geom_density(aes(alpha = 0.6)) + 
  labs(x="Standardised values (mean = 0, sd = 1)", y=element_blank(),
       title="Distributions of outcome variables") +
  scale_fill_ipsum() +
  scale_color_ipsum() +
  guides(color = "none", alpha = "none") +
  theme_ipsum(plot_title_size = 14) + 
  theme(legend.position = "bottom",
        legend.title = element_blank())

vars1_density
```

Let's also plot the distributions of the predictor variables.

```{r predictor-variables-densityplots, message=FALSE, warning=FALSE}

vars1_density<- df %>%
  select(SpeededIP, StrategicIP, Percep, Caution, Discount) %>%
  pivot_longer(., cols = c(SpeededIP, StrategicIP, Percep, Caution, Discount), 
               names_to = "Variable", values_to = "Value") %>%
  ggplot(aes(x = Value, fill = factor(Variable))) + 
  geom_density(aes(alpha = 0.4)) + 
  labs(x="Standardised values (mean = 0, sd = 1)", y=element_blank(),
       title="Distributions of predictor variables") +
  scale_fill_ipsum() +
  scale_color_ipsum() +
  guides(color = "none", alpha = "none") +
  theme_ipsum(plot_title_size = 14) + 
  theme(legend.position = "bottom",
        legend.title = element_blank())

vars1_density
```

Have a first visual look of the association between the variables.

```{r create-scatterplots, message=FALSE, warning=FALSE}

# predictor and outcome variables
predictors <- c("SpeededIP", "StrategicIP", "Percep", "Caution", "Discount")
outcomes <- c("Conservatism", "Authoritarianism", "Dogmatism")

# list to store sub-lists of plots (one list per outcome variable)
plots_lists <- vector("list", length(outcomes))
names(plots_lists) <- outcomes

for (outcome in outcomes) {
  # Initialize an empty list to store plots for this particular outcome
  plots <- list()
  
  for (predictor in predictors) {
    # Generate the plot for this predictor-outcome pair
    plot <- ggplot(df, aes_string(x = predictor, y = outcome)) +
      geom_point(size = 1) +
      geom_smooth(method = "lm") +
      labs(x = predictor, y = outcome,
           title = paste(predictor, "and", outcome)) +
      scale_fill_ipsum() +
      scale_color_ipsum() +
      guides(color = "none", alpha = "none") +
      theme_ipsum(plot_title_size = 12)
      
    # Add the plot to the list of plots
    plots[[predictor]] <- plot
  }
  
  # Combine all plots for this outcome into a single patchwork object
  plots_lists[[outcome]] <- reduce(plots, `+`)
}
```

```{r conservatism-scatterplots, message=FALSE, warning=FALSE, fig.height=8, fig.width=12}

print(plots_lists[["Conservatism"]])
```

```{r authoritarianism-scatterplots, message=FALSE, warning=FALSE, fig.height=8, fig.width=12}

print(plots_lists[["Authoritarianism"]])
```

```{r dogmatism-scatterplots, message=FALSE, warning=FALSE, fig.height=8, fig.width=12}

print(plots_lists[["Dogmatism"]])
```

Now that we have a first descriptive impression of what the relationships may look like, let's start with the first model.

### Frequentist multiple linear regression: The associations between cognitive factors and political conservatism

This time, I will also fit a linear regressions using the frequentist lm() function. We will use the results from this to make comparisons to the Bayesian approach. We start the following model:

`Conservatism ~ SpeededIP + StrategicIP + Percep + Caution + Discount + Gender + Age + Edu + Income` and will compare the coefficients for the dataset in which all continuous input variables were scaled by 2 SD with the one in which they were scaled by 2 SD.

```{r frequentist-mlr-con-sd2}

f_m1_con <- lm(Conservatism ~ SpeededIP + StrategicIP + Percep + Caution + Discount + Gender + Age + Edu + Income, data = d)

summary(f_m1_con)
```

We can see that there is a statistically significant effect (with $\alpha = 0.05$) for StrategicIP and Caution, as well as Age.

We will not go into detail for now, but let's also fit the same regression on the data that was standardized to have a SD = 1.

```{r frequentist-mlr-con-sd1}

f_m2_con <- lm(Conservatism ~ SpeededIP + StrategicIP + Percep + Caution + Discount + Gender + Age + Edu + Income, data = d1sd)

summary(f_m2_con)
```

Alright, makes sense. If we scale the input variables by 2 SD, the estimates are exactly two times as large, a change of 2 SD of the predictor reflect a change of X SD in the outcome.

If we scale the input by one SD, a change of 1 SD of the predictor variables reflect a change of X SD in the outcome.

Let's check what happens when we scale the input variables by 1 SD, but set up sum-coding for the categorical variables.

```{r frequentist-mlr-con-sum}

f_m3_con <- lm(Conservatism ~ SpeededIP + StrategicIP + Percep + Caution + Discount + Gender + Age + EduFactor + Income, data = df)

summary(f_m3_con)
```

We achieved the same thing! But its actually a bit easier to interpret effects now. So I think I actually prefer this way and will stick with it for now. We scale our input variables by 1 SD, and use sum-coding for our binary predictor variables.

Now that we cleared this - let's finally get to the point of this blog post.

### Bayesian multiple linear regression

Alright, let's do the same but in the Bayesian framework. For now, we will stick again and investigate the associations of the cognitive factors with political conservatism while controlling for the effects of the confounding variables.

#### Selecting priors

I already scaled all variables of interest. This will make it a bit simpler to select priors. I will use weakly informative priors for our slope and intercept parameters (see <https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations>). The selected prior is $N(0,1)$. Let's plot to prior to see what kind of an effect it may have on our parameters.

```{r plt-priors, message=FALSE, warning=FALSE}

colors <- ipsum_pal()(1)

prior(normal(0, 1)) %>% 
  parse_dist() %>% 
  
  ggplot(aes(xdist = .dist_obj, y = prior)) + 
  stat_halfeye(.width = 0.683, p_limits = c(.001, .999), 
               slab_fill = colors[1], slab_alpha = 0.8) +
  scale_y_discrete(NULL, breaks = NULL, expand = expansion(add = 0.1)) +
  labs(title = "Prior N(0,1)", x = "Parameter Space", y = "") +
  coord_cartesian(xlim = c(-4, 4)) +
  scale_x_continuous(breaks = seq(-4, 4, by = 1)) +
  theme_ipsum() +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) 
```

We can see that in the the plot for $N(0,1)$, more density is around 0. As we expect our parameter values to be between -1 and 1, this gives more weight to parameter values closer to zero, and less weight to parameter values that are far from zero.

Let's check how our priors are set by default in `brms`.

```{r check-default-priors}
get_prior(Conservatism ~ SpeededIP + StrategicIP + Percep + Caution + Discount + Gender + Age + EduFactor + Income, data = df)
```

By default `brms` sets non-informative flat priors for our slope parameters. We thus have to change this, and can do so directly when fitting the model.

#### Fitting and summarising the first model

```{r model1.1-fitting}
m1.1 <- brm(Conservatism ~ SpeededIP + StrategicIP + Percep + Caution + Discount + Gender + Age + EduFactor + Income, 
          data = df, 
          prior = c(prior(normal(0, 1), class = "Intercept"), 
                    prior(normal(0, 1), class = "b")),
          seed = bayes_seed,
          file = "02_fits/fit_m1.1")
```

We get a warning message:

```         
Warning: Rows containing NAs were excluded from the model.
```

We are not happy with this, but for now we will deal with it later.

Check the results. We can use either `summary(m1.1)` or `print(m1.1)` to do so.

```{r model1.1-results}
summary(m1.1, prob = 0.95)  # prob = 0.95 is the default
```

Use the tools from `bayestestR` to have another look at the posterior. We also define a region of practical equivalence ranging from \[-0.05; 0.05\].

More on this later.

```{r m1.1-bayestestR}
m1.1_posteriors <- describe_posterior(m1.1, 
                                      centrality = "median",
                                      dispersion = FALSE,
                                      ci = 0.95,
                                      ci_method = "hdi",
                                      test = c("rope"),
                                      rope_range = c(-0.05, 0.05),
                                      rope_ci = 1)

m1.1_posteriors <- as.data.frame(m1.1_posteriors)
m1.1_posteriors %>% 
  select(Parameter, Median, CI_low, CI_high, ROPE_Percentage) %>% 
  tt(.)
```

Plot the conditional effects - for now just plot those of strategic information processing, this predictor seems to be largest in size. Let's borrow some code (as often) from [great open resources](https://bookdown.org/content/3686/metric-predicted-variable-with-one-metric-predictor.html#simple-linear-regression).

First load some fancy colors from the [beyonce package](https://github.com/dill/beyonce).

```{r color-palette, message=FALSE, warning=FALSE}
# devtools::install_github("dill/beyonce")
library(beyonce)

bp <- beyonce_palette(41, n = 9, type = "continuous")
bp
```

Let's gather the draws from our model as a dataframe.

```{r wide-draws}
w_draws <- as_draws_df(m1.1)
head(w_draws)
```

Let's first replicate the plot from above.

```{r man-con-eff-plot-speed}

# how many posterior lines would you like?
n_lines <- 200

df %>% 
  ggplot(aes(x = StrategicIP, y = Conservatism)) +
  geom_abline(data = w_draws %>% slice(1:n_lines),
              aes(intercept = b_Intercept, slope = b_StrategicIP, group = .draw),
              color = bp[2], linewidth = 1/4, alpha = 1/4) + 
  geom_point(alpha = 1/2, color = bp[5]) +
  labs(title = "Conditional association between StrategicIP and Conservatism",
       caption = (paste("Data with", n_lines, "credible regression lines")),
       x = "Strategic",
       y = "Conservatism") +
  coord_cartesian(xlim = c(-5, 5),
                  ylim = c(-3, 3)) +
  theme_ipsum(plot_title_size = 12,
              axis_title_size = 10,
              axis_title_face = "bold") +
  theme(panel.grid.minor = element_blank()) 
```

Let's also plot the conditional association between Age and Conservatism. As we standardized the variable Age, but Age in years is more intuitive for interpretations, let's rescale the draws first.

```{r rescale-predictor-slope}

# make a function to rescale slope estimates
make_beta_1 <- function(zeta_1, sd_x, sd_y) {
  zeta_1 * sd_y / sd_x
}

# this is not super elegant but I add Conservatism scaled to the first data as in df I only have the scaled variable - note for future do not change orig variable
data <- data %>% 
  mutate(Conservatism_z = scale(Conservatism))

# calculate the sd of x and y
sd_x <- sd(data$Age, na.rm = T)
sd_y <- sd(data$Conservatism_z, na.rm = T)

# rescale the posterior draws of Age
w_draws <-
  w_draws %>% 
  mutate(b_Age_orig = make_beta_1(zeta_1 = b_Age,
                                  sd_x   = sd_x,
                                  sd_y   = sd_y))

w_draws %>% 
  select(b_Age, b_Age_orig) %>% 
  head(.) %>% 
  tt(.)
```

Now we are ready to create a prettier plot from our manual draws for Age.

```{r man-con-eff-plot-Age}

# how many posterior lines would you like?
n_lines <- 200

data %>% 
  ggplot(aes(x = Age, y = Conservatism_z)) +
  geom_abline(data = w_draws %>% slice(1:n_lines),
              aes(intercept = b_Intercept, slope = b_Age_orig, group = .draw),
              color = bp[2], linewidth = 1/4, alpha = 1/4) + 
  geom_point(alpha = 1/2, color = bp[5]) +
  labs(title = "Conditional association between Age and Conservatism",
       caption = (paste("Data with", n_lines, "credible regression lines")),
       x = "Age",
       y = "Conservatism") +
  coord_cartesian(xlim = c(18, 65),
                  ylim = c(-3, 3)) +
  theme_ipsum(plot_title_size = 12,
              axis_title_size = 10,
              axis_title_face = "bold") +
  theme(panel.grid.minor = element_blank()) 
```

Let's also plot the conditional effects for our factor variables and see how those plots look like. For this we use the inbuilt function conditional_effects().

```{r conditional-effects-factors, message=FALSE, warning=FALSE, fig.width=14, fig.height=10}

c_eff_m1.1 <- conditional_effects(m1.1)

c_eff_m1.1_plot_gen <- plot(c_eff_m1.1, 
                        points = T,
                        point_args = list(size = 1, alpha = 1/4, width = .05, height = .05, color = "black"),
                        plot = FALSE)[[6]] +
  scale_color_ipsum() +
  scale_fill_ipsum() +
  theme_ipsum()


c_eff_m1.1_plot_edu <- plot(c_eff_m1.1, 
                        points = T,
                        point_args = list(size = 1, alpha = 1/4, width = .05, height = .05, color = "black"),
                        plot = FALSE)[[8]] +
  scale_color_ipsum() +
  scale_fill_ipsum() +
  theme_ipsum()
  
c_eff_m1.1_plot_gen + c_eff_m1.1_plot_edu
```

Let's use `bayesplot` functions to plot the posterior distributions of the parameters.

```{r m1.1_mcmc-plot, message=FALSE, warning=FALSE}

mcmc_plot(m1.1, 
          type = "areas") +
  theme_ipsum()
```

We can also manually create a similar plot using draws from the posterior distribution. For simplicity, Here we use `gather_draws` from the `tidybayes` package - this automatically returns a long dataframe suitable for plotting in ggplot.

```{r m1.1_mcmc-plot-manual, fig.height=5.5, fig.width=8.5, message=FALSE, warning=FALSE}

# gather draws in a long format
draws_m1.1 <- m1.1 %>% 
  gather_draws(`b_.*`, regex = TRUE)  %>% 
  filter(.variable %in% c("b_SpeededIP", "b_StrategicIP", "b_Percep", "b_Caution", "b_Discount")) %>%
  mutate(.variable = case_when(
    .variable == "b_SpeededIP" ~ "Speed of Evidence Accumulation",
    .variable == "b_StrategicIP" ~ "Strategic Information Processing",
    .variable == "b_Percep" ~ "Perceptual Processing Time",
    .variable == "b_Caution" ~ "Caution",
    .variable == "b_Discount" ~ "Discount",
    TRUE ~ .variable # keeps the original value if none of the conditions are met
  ))  %>%
  mutate(.variable = factor(.variable, levels = c(
    "Speed of Evidence Accumulation",
    "Strategic Information Processing",
    "Perceptual Processing Time",
    "Caution",
    "Discount"
  )))

ggplot(draws_m1.1, aes(x = .value, y = fct_rev(.variable), fill = .variable)) +
  geom_rect(aes(xmin = -0.05, xmax = 0.05, ymin = -Inf, ymax = Inf), 
            color = "transparent", fill = bp[9], alpha = 0.05) +
  geom_vline(xintercept = 0, alpha = 0.2) +
  stat_halfeye(slab_alpha = 0.8,
               .width = c(0.9, 0.95), point_interval = "median_hdi") +
  scale_fill_manual(values = beyonce_palette(41, n = 7, type = "continuous")) +
  guides(fill = "none", slab_alpha = "none", alpha = "none") +
  labs(title = "Associations of Cognitive Factors with Political Conservatism", 
       x = "Posterior Distribution", 
       y = "Variable",
       caption = "90% and 95% credible intervals shown in black.") +
  scale_x_continuous(breaks = seq(-0.50, 0.50, by = 0.1)) +
  coord_cartesian(xlim = c(-0.45, 0.45)) +
  theme_ipsum(plot_title_size = 14,
              axis_title_size = 12,
              axis_title_face = "bold") +
  annotate("text", x = 0, y = 0.6, label = "ROPE", 
            color = "black", size = 5)
```

#### Interpretation of the findings

Let's make some sense of the findings.

```{r interpretation, include=FALSE}

m1.1_posteriors <- m1.1_posteriors %>% 
  mutate(across(where(is.numeric), ~round(.x, 2)))

strIP_median <- m1.1_posteriors %>% 
  filter(Parameter == "b_StrategicIP") %>% 
  pull(Median)

strIP_cil <- m1.1_posteriors %>% 
  filter(Parameter == "b_StrategicIP") %>% 
  pull(CI_low)

strIP_cih <- m1.1_posteriors %>% 
  filter(Parameter == "b_StrategicIP") %>% 
  pull(CI_high)

cau_median <- m1.1_posteriors %>% 
  filter(Parameter == "b_Caution") %>% 
  pull(Median)

cau_cil <- m1.1_posteriors %>% 
  filter(Parameter == "b_Caution") %>% 
  pull(CI_low)

cau_cih <- m1.1_posteriors %>% 
  filter(Parameter == "b_Caution") %>% 
  pull(CI_high)
```

The model indicates that there is a high probability given the data that Strategic Information Processing (Median = `r sprintf("%.2f", strIP_median)` , 95% CI `r paste0("[", sprintf("%.2f", strIP_cil), "; ", sprintf("%.2f", strIP_cih), "]",")")` is negatively associated with Conservatism, and that in turn, Caution (Median = `r sprintf("%.2f", cau_median)` , 95% CI `r paste0("[", sprintf("%.2f", cau_cil), "; ", sprintf("%.2f", cau_cih), "]", ")")` is positively associated with Conservatism.

#### Checking the model

##### Prior check

Let's check if the prior that we used for the slope and intercept was informative or, as intended, only weakly informative. We can use functionality from `bayestestR` for this.

```{r m1.1-prior-check}

prior_summary(m1.1)
check_prior(m1.1)
```

Ok - as intended our priors were uninformative.

##### Posterior predictive check

Let's also check how well our model performs in generating data that is similar to our observed data. We call this a **Posterior predictive check (PPC)**.

```{r m1.1-ppc1, message=FALSE, warning=FALSE}
pp_check(m1.1, ndraws = 100)
```

Our model seems to capture the shape of the observed data well.

```{r m1.1-ppc2, message=FALSE, warning=FALSE}
pp_check(m1.1, ndraws = 100, type ='error_scatter_avg', alpha = .1)
```

##### Trace plot

Commonly, we look at the trace plots, i.e., the estimated values across each iteration for a chain. See [this nice practical guide by Michael Clark](https://m-clark.github.io/posts/2021-02-28-practical-bayes-part-i/#rhat-effective-sample-size) for some details. We will follow his code in several steps below.

What should the trace plot look like? Ideally it should look like a series from a normal distribution.

```{r traceplot, message=FALSE, warning=FALSE}
qplot(x = 1:1000, y = rnorm(1000), geom = 'line') +
  theme_ipsum()
```

Now we can also plot the trace plot from our model, using nice functionality from `bayesplot`.

```{r m1.1-traceplot, warning=FALSE, message=FALSE, fig.height = 10, fig.width=14}
mcmc_plot(m1.1, type = 'trace') +
  theme_ipsum()
```

This looks good too.

### Time to go Multivariate

Ok - but what if we want to investigate the effects of multiple predictors on multiple outcomes at the same time? `brms` allows us to run a multivariate multiple regression! So we can do just that.

We will keep it a bit brief here, but may delve into this a bit more in future blog posts.

Start with formulating our model. We want to investigate the relative controlled associations between the five Cognitive Factors and Conservatism, Authoritarianism and Dogmatism at the same time.

```{r multivariate-formula}
f_mv1 <- 
  bf(mvbind(Conservatism, Authoritarianism, Dogmatism) 
     ~ SpeededIP + StrategicIP + Percep + Caution + Discount + 
       Gender + Age + EduFactor + Income) +
  set_rescor(TRUE)
```

Let's have a look at the default priors.

```{r mv-default-priors}
get_prior(data = df,
          family = gaussian,
          formula = f_mv1)
```

Again, we want to set the priors for the intercepts and slopes to $N(0, 1)$.

Let's fit the model.

```{r mv1-fitting}
mv1 <- brm(data = df,
           family = gaussian,
           formula = f_mv1,
           prior = c(prior(normal(0, 1), class = "Intercept"),
                     prior(normal(0, 1), class = "b")),
          seed = bayes_seed,
          file = "02_fits/fit_mv1")
```

Let's have a look at the output.

```{r mv1-summary}
summary(mv1)
```

```{r mv1-bayestestR}
mv1_posteriors <- describe_posterior(mv1, 
                                     centrality = "median",
                                     dispersion = FALSE,
                                     ci = 0.95,
                                     ci_method = "hdi")

mv1_posteriors <- as.data.frame(mv1_posteriors)
mv1_posteriors %>% 
  select(Parameter, Median, CI_low, CI_high) %>% 
  mutate(across(where(is.numeric), ~round(.x, 2))) %>% 
  tt(.)
```

We cannot directly check the percentage in the ROPE using the `describe_posterior` function for multivariate models yet - it will throw a warning. But we can use the `rope` function from the `bayesTestR` package.

```{r mv-rope}
rope(mv1, 
     range = list(Conservatism = c(-0.05, 0.05), 
                  Authoritarianism = c(-0.05, 0.05), 
                  Dogmatism = c(-0.05, 0.05)), 
     ci = 1, ci_method = "HDI")
```

Let's also create the same plot as before.

```{r mv1-draws}

draws_mv1 <- mv1 %>%  
  gather_draws(`b_.*`, regex = TRUE) %>% 
  # for the plot I want to remove the intercepts
  filter(!str_detect(.variable, "Intercept")) %>%
  # create a new variable that captures which outcome
  mutate(outcome = case_when(
    str_detect(.variable, "Conservatism") ~ "Conservatism",
    str_detect(.variable, "Authoritarianism") ~ "Authoritarianism",
    str_detect(.variable, "Dogmatism") ~ "Dogmatism")) %>% 
  # create a new variable that captures which predictor
  mutate(predictor = case_when(
    str_detect(.variable, "SpeededIP") ~ "Speed of Evidence Accumulation",
    str_detect(.variable, "StrategicIP") ~ "Strategic Information Processing",
    str_detect(.variable, "Percep") ~ "Perceptual Processing Time",
    str_detect(.variable, "Caution") ~ "Caution",
    str_detect(.variable, "Discount") ~ "Discount")) %>% 
  # create a new variable that captures which confounder
  mutate(confounder = case_when(
    str_detect(.variable, "Age") ~ "Age",
    str_detect(.variable, "Gender1") ~ "Gender",
    str_detect(.variable, "EduFactor1") ~ "Education Level 1",
    str_detect(.variable, "EduFactor2") ~ "Education Level 2",
    str_detect(.variable, "Income") ~ "Income")) %>% 
  # set them as factors with specific levels
  mutate(outcome = factor(outcome, levels = c(
    "Conservatism",
    "Authoritarianism",
    "Dogmatism"))) %>% 
  mutate(predictor = factor(predictor, levels = c(
    "Speed of Evidence Accumulation",
    "Strategic Information Processing",
    "Perceptual Processing Time",
    "Caution",
    "Discount"))) %>% 
  mutate(confounder = factor(confounder, levels = c(
    "Age",
    "Gender",
    "Education Level 1",
    "Education Level 2",
    "Income"))) 

glimpse(draws_mv1)
```

```{r mv-plot, fig.height=8, fig.width=12, message=FALSE, warning=FALSE}
draws_mv1 %>% 
  # drop NA (= predictors that I will not need) 
  drop_na(predictor) %>%
  ggplot(aes(x = .value, y = fct_rev(predictor), fill = predictor)) +
  geom_rect(aes(xmin = -0.05, xmax = 0.05, ymin = -Inf, ymax = Inf), 
            color = "transparent", fill = bp[9], alpha = 0.05) +
  geom_vline(xintercept = 0, alpha = 0.8) +
  stat_halfeye(slab_alpha = 0.8,
               .width = c(0.9, 0.95), point_interval = "median_hdi") +
  scale_fill_manual(values = beyonce_palette(41, n = 7, type = "continuous")) +
  guides(fill = "none", slab_alpha = "none", alpha = "none") +
  labs(title = "Associations of Cognitive Factors with Ideological Attitudes", 
       x = "Posterior Distribution", 
       y = "Predictor Variable",
       caption = "90% and 95% credible intervals shown in black.") +
  scale_x_continuous(breaks = seq(-0.50, 0.50, by = 0.1)) +
  coord_cartesian(xlim = c(-0.45, 0.45)) +
  theme_ipsum(plot_title_size = 16,
              axis_title_size = 14,
              axis_title_face = "bold") +
  annotate("text", x = 0, y = 0.6, label = "ROPE", 
            color = "black", size = 4) +
  facet_wrap(~ outcome, nrow=2)
```

Very nice! From the plot we can directly infer that Strategic Information Processing is the most important predictor of Conservatism - this is also the overall most relevant effect! Our cognitive predictors do a worse job at predicting Authoritarianism or Dogmatism.

What about our demographic predictor variables?

```{r dem-mv-plot, fig.height=8, fig.width=12, message=FALSE, warning=FALSE}
draws_mv1 %>% 
  # drop NA (= predictors that I will not need) 
  drop_na(confounder) %>%
  ggplot(aes(x = .value, y = fct_rev(confounder), fill = confounder)) +
  geom_rect(aes(xmin = -0.05, xmax = 0.05, ymin = -Inf, ymax = Inf), 
            color = "transparent", fill = bp[9], alpha = 0.05) +
  geom_vline(xintercept = 0, alpha = 0.8) +
  stat_halfeye(slab_alpha = 0.8,
               .width = c(0.9, 0.95), point_interval = "median_hdi") +
  scale_fill_manual(values = beyonce_palette(8, n = 5, type = "continuous")) +
  guides(fill = "none", slab_alpha = "none", alpha = "none") +
  labs(title = "Associations of Demographic Factors with Ideological Attitudes", 
       x = "Posterior Distribution", 
       y = "Predictor Variable",
       caption = "90% and 95% credible intervals shown in black.") +
  scale_x_continuous(breaks = seq(-0.50, 0.50, by = 0.1)) +
  coord_cartesian(xlim = c(-0.45, 0.45)) +
  theme_ipsum(plot_title_size = 16,
              axis_title_size = 14,
              axis_title_face = "bold") +
  annotate("text", x = 0, y = 0.6, label = "ROPE", 
            color = "black", size = 4) +
  facet_wrap(~ outcome, nrow=2)

```

Very neat! We see that there is a relatively high probability that Age is positively associated with Conservatism - this appears to be the most relevant effect again.

#### Checking the model

The model did not throw any warnings, so I will let you check convergence etc. by yourself if you want to.

But let's have a final look at the posterior predictive check:

```{r mv1-ppc1, message=FALSE, warning=FALSE}
pp_check(mv1, ndraws = 100, resp="Conservatism")
```

```{r mv1-ppc2, message=FALSE, warning=FALSE}
pp_check(mv1, ndraws = 100, resp="Authoritarianism")
```

It seems like the model does a bit worse at capturing Authoritarianism. This may be as Authoritarianism is actually a ordinal variable here that can only take the values 1, 2, 3, 4.

```{r mv1-ppc3, message=FALSE, warning=FALSE}
pp_check(mv1, ndraws = 100, resp="Dogmatism")
```

### Indirect associations?

One thing that I did not talk about is that brms also allows to test indirect effects. Before conducting the study, we may have expected that Age is indirectly associated with Conservatism via cognitive abilities. In a causal analysis this would be called `mediation`, but for here I just want to say: Before you do something like this, try to make yourself aware of the conclusions that you can draw from such analyses in observational data. I may delve a bit deeper into this in a future blog post, but for now here are three reads I can highly recommend:

-   [That’s a Lot to Process! Pitfalls of Popular Path Models by Rohrer et al. (2022)](https://journals.sagepub.com/doi/10.1177/25152459221095827)
-   [Thinking Clearly About Correlations and Causation: Graphical Causal Models for Observational Data, again by Rohrer (2018)](https://journals.sagepub.com/doi/full/10.1177/2515245917745629)
-   And as many people criticize statistical models that test for indirect associations in cross-sectional data, [here a bit of a different view on it](https://www.daviddisabato.com/blog/2016/5/22/the-double-standard-against-cross-sectional-mediation).

## Sources and Resources

I am not a statistician, so please take all of what I wrote and coded here with a lot of caution. However, there are many great resources out there if you want to delve deeper into the topic - I am just getting started with this, but here are a few potentially helpful links.

-   [*Doing Bayesian Data Analysis* in brms and the tidyverse](https://bookdown.org/content/3686/): A brms and tidyverse version by Solomon Kurz of the classic book by Kruschke [*Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan*](https://sites.google.com/site/doingbayesiandataanalysis/). 

-   [Practical Bayes Part I](https://m-clark.github.io/posts/2021-02-28-practical-bayes-part-i/#rhat-effective-sample-size) and [Practical Bayes Part II](https://m-clark.github.io/posts/2021-02-28-practical-bayes-part-ii/): Great resources to dealing and avoiding common problems in Bayesian models by Micheal Clark

-   [Bayesian Basics](https://m-clark.github.io/bayesian-basics/preface.html): General overview of how to run Bayesian models in R

-   [bayestestR](https://easystats.github.io/bayestestR/index.html): Vignettes on basic Bayesian models and their interpretation

-   [Stan Wiki: Prior Choice](https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations): Go to reference for selecting priors

-   [Course Handouts for Bayesian Data Analysis Class](https://bookdown.org/marklhc/notes_bookdown/) by Mark Lai

And there are of course many many more resources, this is just to get started with some.
