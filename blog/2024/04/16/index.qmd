---
title: "Teaching Myself: Bayesian Path Modeling in blavaan and brms"
author: "Olaf Borghi"
date: 2024-04-16
description: "In previous blog posts, I looked into Bayesian linear regression - with a single predictor, multiple predictors, and a single and multiple outcome variables. blavaan and brms also allow to specify path models (i.e., structural equation models without latent variables) that allow to investigate more complex relationships between variables."
categories:
  - r
  - Bayes
  - Path model
  - brms
  - blavaan 
freeze: true
format:
  html:
    toc-depth: 4
embed-resources: true
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
# knit settings
knitr::opts_chunk$set(fig.align = "center", fig.retina = 3,
                      fig.width = 6, fig.height = (6 * 0.618),
                      out.width = "90%", collapse = TRUE)
options(digits = 3, width = 90)

# set error messages to English
Sys.setenv(LANG = "en")

# Make all the random draws reproducible
set.seed(42)
```

```{r libraries, warning=FALSE, message=FALSE}
# use groundhog to make code maximally reproducible
if (!require("groundhog", quietly = TRUE)) {
  install.packages("groundhog")
}
library("groundhog")

# use groundhog to install and load packages - we may not use all of them and some consider it bad practise
# to still load them, but all of them are nice to have and could be useful
pkgs <- c("here",         # System path management
          "tidyverse",    # ggplot, dplyr, %>%, and friends
          "easystats",    # bayestestR, performance, effectsize and friends
          "modelsummary", # Data and model summaries with tables and plots
          "psych",        # Descriptive statistics and other tools
          "brms",         # Bayesian modeling through Stan
          "blavaan",      # Bayesian SEM
          "lavaan",       # Frequentist SEM
          "semPlot",      # Plots for SEM
          "tidybayes",    # Integration of Bayesian models in tidy + ggplot workflow
          "broom",        # Convert model objects to data frames
          "broom.mixed",  # Convert brms model objects to data frames
          "tinytable",    # Lightweight package to create tables
          "hrbrthemes",   # Additional ggplot themes
          "extrafont",    # Additional fonts for plots etc
          "ggdist",       # Special geoms for posterior distributions
          "ggrepel",      # Automatically position labels
          "gghalves",     # Special half geoms
          "patchwork"     # Combine ggplot objects
          )

groundhog.library(pkgs, "2024-03-01") # change to a recent date
```

```{r loadfonts, include=FALSE}
loadfonts(quiet = TRUE)
```

```{r Stan backend, include=FALSE}
# you may also use the faster cmdstanr backend for Stan in the place of rstan
# Yto do so install the cmdstanr package first: https://mc-stan.org/cmdstanr/
# Then run cmdstanr::install_cmdstan() to install cmdstan on your computer.

options(mc.cores = 4,  # Use 4 cores
        brms.backend = "rstan")
bayes_seed <- 42
```

## Teaching Myself: Bayesian Path Modeling

Using the same dataset as in previous blog posts, this time I will look into path models within a Bayesian statistical framework. Path models allow to directly check complex models, including associations between multiple predictors, multiple outcomes, and indirect associations.

I will not touch upon the topics of causality etc. here. However, I want to point out that before running a path model, one should carefully think about the relationships of interest. In addition, analyses of indirect effects are often called "mediation analysis". Some use mediation in a merely causal context, and as I don't touch causality here, I will stick to the term "indirect association". Path models on cross-sectional data are also criticized from time to time, so here a few suggested reads before you think of doing this in your own research:

-   [That’s a Lot to Process! Pitfalls of Popular Path Models by Rohrer et al. (2022)](https://journals.sagepub.com/doi/10.1177/25152459221095827)
-   [Thinking Clearly About Correlations and Causation: Graphical Causal Models for Observational Data, again by Rohrer (2018)](https://journals.sagepub.com/doi/full/10.1177/2515245917745629)
-   And as many people criticize statistical models that test for indirect associations in cross-sectional data, [here a bit of a different view on it](https://www.daviddisabato.com/blog/2016/5/22/the-double-standard-against-cross-sectional-mediation).

**So beware: This blog post is mainly about messing around with some data and trying out different functions!**

Specifically, we want to investigate whether there is an indirect association between Age and Conservatism, Dogmatism, and Religiosity via five cognitive factors Caution, Temporal Discounting, Perceptual Processing Time, Speed of Evidence Accumulation, and Strategic Information Processing (Self-regulation ontology; see Eisenberg et al., [2018](https://www.sciencedirect.com/science/article/abs/pii/S0005796717302048); [2019](https://www.nature.com/articles/s41467-019-10301-1))

### Meet the data

I will again use open data from [Zmigrod et al. (2021)](https://zenodo.org/records/4434725/files/Data%20-%20Zmigrod%20et%20al%202021%20Philosophical%20Transactions.xlsx?download=1). This dataset includes cognitive and personality factors derived from exploratory factor analysis (EFA) of a large number of behavioral cognitive tasks and personality questionnaires from the Self-Regulation Ontology and in addition to that, several measures of ideology.

```{r Load data, include=FALSE}
data_path <- here("01_data", "ideology_data.csv")
data <- read_csv(data_path)
```

### Some preparations and explorations

#### Exploratory factor analysis

I will directly re-use some of the code that was shared together with the manuscript (Zmigrod et al., 2021; see above) to obtain three ideology factors using EFA on the scores of several questionnaires.

```{r run-EFA}
# create df with relevant data for EFA 
efa_data <- data.frame(
        secs_social = data$SocialConservatism, 
        secs_econ = data$EconConservatism,
        nation = data$Nationalism, 
        auth = data$Authoritarianism,
        SJ = data$SJ, 
        sdo = data$SDO,
        patriot = data$Patriotism,
        progrSum = data$IngroupAttitude, #
        dogma = data$Dogmatism,
        IH1 = -1*data$IH1, # IH factors reversed because conceptually inverse of dogmatism
        IH2 = -1*data$IH2,
        IH3 = -1*data$IH3,
        IH4 = -1*data$IH4,
        rel_atten = data$ReligiousAttendance,
        rel_pray = data$ReligiousPrayer,
        rel_imp = data$ReligionImportance
      )

# run EFA 
scree(efa_data) # scree plot
fa.parallel(efa_data, fm = "ml") # parallel analysis
Ideol_EFA <- fa(efa_data, 
                nfactors=3, 
                rotate="oblimin")     # EFA oblimin for 3 factors

print.psych(Ideol_EFA)
```

Alright, just as in the manuscript the EFA indicates three factors, the first appears to be a factor of political conservatism, as there are high loadings of social and economic conservatism, nationalism, religiosity on this factor. The second appears to be a factor of dogmatism, with high loadings of the dogmatism and intellectual humility measure. The third appears to be a religiosity factor.

If you want to explore EFA a bit more, here again a suggested read [Factor Analysis with the psych package by Micheal Clark](https://m-clark.github.io/posts/2020-04-10-psych-explained/). For now we don't really care that much about the details, all we want are the three factor scores so that we can explore a few path models.

```{r add-factor-scores-to-data}
# obtain factor loadings and add them to data
factor_scores <- as.data.frame(Ideol_EFA$scores)

data <- add_column(
  data, 
  conservatism_factor = factor_scores$MR1, 
  dogmatism_factor = factor_scores$MR2, 
  religiosity_factor = factor_scores$MR3  
  )
```

#### Standardizing the data

Again, I will standardize the data. The scales are arbitrary anyway in this case, and this simplifies specifying the priors in this very basic example.

```{r select-and-scale}
df <- data %>%
  select(1, 3:11, 59:61) %>%
  rename(ID = SubjectN) %>% 
  mutate(Edu = as.factor(Edu),
         Gender = as.factor(Gender),
         ID = as.factor(ID)) %>% 
  mutate(across(where(is.numeric), scale))

str(df)
```

#### Descriptive analyses

I recently learned about the [modelsummary](https://modelsummary.com/) package, and it looks very very nice. So let's try to create a descriptive table using the package.

```{r modelsummary-descriptives}
df %>% 
  select(Age, Income, SpeededIP, StrategicIP, Percep, Caution, Discount, conservatism_factor, dogmatism_factor, religiosity_factor) %>% 
  datasummary_skim(.)
```

Ok, this is actually super super cool! We can also summarize the categorical variables. By default `datasummary_skim` will only summarize numerical variables (above I selected a few specific variables of interest on purpose). We can also tell it to just summarize categorical variables:

```{r modelsummary-descriptives-cat}
datasummary_skim(df, type = "categorical")
```

Again, this is so so cool! I am a big fan of the package already! Let's see if we can find some more use for it a bit later.

## Ready for the Path Models?

### Using lavaan for frequentist path models

Path models can also be seen as structural equation models with only observed and no latent variables. They do not model measurement error in a way as latent variable models do, but are thus usually also a bit less complex. We will first run a simple path model in lavaan, and then try to replicate the findings in brms and blavaan. Also, for now we will not control for demographic variables.

Let's specify our lavaan model.

```{r path-model-syntax}
model1 <- 
' 
# direct associations (outcome ~ direct predictor)
    conservatism_factor ~ c1*Age
    dogmatism_factor ~ c2*Age
    religiosity_factor ~ c3*Age
  
# indirect associations (indirect predictor ~ direct predictor)
    SpeededIP ~ a1*Age
    StrategicIP ~ a2*Age
    Percep ~ a3*Age
    Caution ~ a4*Age
    Discount ~ a5*Age
    
# indirect associations (outcome ~ indirect predictor)
    conservatism_factor ~ b11*SpeededIP + b12*StrategicIP + b13*Percep + b14*Caution + b15*Discount
    dogmatism_factor ~ b21*SpeededIP + b22*StrategicIP + b23*Percep + b24*Caution + b25*Discount
    religiosity_factor ~ b31*SpeededIP + b32*StrategicIP + b33*Percep + b34*Caution + b35*Discount
    
# residual covariances

# mediator residual covariance
    SpeededIP ~~ StrategicIP + Percep + Caution + Discount
    StrategicIP ~~ Percep + Caution + Discount
    Percep ~~ Caution + Discount
    Caution ~~ Discount

# dependent residual covariance
    conservatism_factor ~~ dogmatism_factor + religiosity_factor
    dogmatism_factor ~~ religiosity_factor
    
# effect decomposition
# x = age, m1 = SpeededIP, m2 = StrategicIP, m3 = Percep, m4 = Caution, m5 = Discount
  
# y1 = conservatism_factor;  
    ind_x_m1_y1 := a1*b11
    ind_x_m2_y1 := a2*b12
    ind_x_m3_y1 := a3*b13
    ind_x_m4_y1 := a4*b14
    ind_x_m5_y1 := a4*b15
    ind_x_y1 := ind_x_m1_y1 + ind_x_m2_y1 + ind_x_m3_y1 + ind_x_m4_y1 + ind_x_m5_y1
    tot_x_y1 := ind_x_y1 + c1
    
# y2 = dogmatism_factor
    ind_x_m1_y2 := a1*b21
    ind_x_m2_y2 := a2*b22
    ind_x_m3_y2 := a3*b23
    ind_x_m4_y2 := a4*b24
    ind_x_m5_y2 := a4*b25
    ind_x_y2 := ind_x_m1_y2 + ind_x_m2_y2 + ind_x_m3_y2 + ind_x_m4_y2 + ind_x_m5_y2
    tot_x_y2 := ind_x_y2 + c2
  
# y3 = religiosity_factor
    ind_x_m1_y3 := a1*b31
    ind_x_m2_y3 := a2*b32
    ind_x_m3_y3 := a3*b33
    ind_x_m4_y3 := a4*b34
    ind_x_m5_y3 := a4*b35
    ind_x_y3 := ind_x_m1_y3 + ind_x_m2_y3 + ind_x_m3_y3 + ind_x_m4_y3 + ind_x_m5_y3
    tot_x_y3 := ind_x_y3 + c3
'
```

Let's fit and run this path model in lavaan.

```{r fit-model1-lavaan}
fit1 <- sem(model = model1, data  = df,
            std.ov = TRUE, mimic = "Mplus", 
            estimator = "ML", missing = "fiml") 
```

```{r parameterestimates-model1-lavaan}
parest1 <- parameterestimates(fit1)
parest1 %>% 
  slice(55:75) %>% 
  select(label, est, se, pvalue, ci.lower, ci.upper) %>% 
  tt(.)
```

Let's remind ourselves of what is what:

x = age, m1 = SpeededIP, m2 = StrategicIP, m3 = Percep, m4 = Caution, m5 = Discount, y1 = conservatism, y2 = dogmatism, y3 = religiosity.

The model indicates

-   Significant, but very small positive indirect associations between Age and Conservatism via the cognitive factors StrategicIP, Caution, and Discount.

-   No significant indirect associations between Age, Dogmatism and Religiosity via cognitive factors.

We can also check a bit more information using `summary`.

```{r fit1-summary}
summary(fit1)
```

Also note: Our model perfectly fits the data, but this is because the model is just-identified (i.e., there are 0 degrees of freedom): Every pair of variable is connected - our model is just a different way to describe the full data. This does not mean that the model syntax is incorrect - this is often the case in models with just observed variables and indirect associations.

There is much more in this output that can be of interest. But as we want to focus on the Bayesian analyses here, let's move on for now.

### blavaan: The Bayesian counterpart of lavaan

Using very similar syntax as lavaan, [blavaan](https://ecmerkle.github.io/blavaan/articles/prior.html) allows us to fit Bayesian structural equation models (or path models as here).

Let's check the default priors of blavaan.

```{r blavaan-dafault-priors}
dpriors()
```

Contrary to brms, in many cases we can use these default priors. We can modify the prior distributions, and in particular, we want to specify the prior of the regressions $\beta$ as $N(0,1)$, as we will later use this prior in brms. It should not matter to much, especilly for the other parameters, but this is also good to try out on how to specify priors.

```{r blavaan-specify-priors}
mydp <- dpriors(beta="normal(0,1)")
mydp
```

Let's try to fit the same model as previously.

```{r blavaan-path-model}
fit2 <- bsem(model1, dp = mydp, data = df)
```

```{r}
summary(fit2)
```

The results are very similar.

### Path models in brms

We can do something very similar also using brms! brms is a very flexible and powerful packages that is very flexible with modeling approaches. I think blavaan is the more straight-forward choice as soon as you want to specifiy latent variable models, but for models with just observed variables brms may even be the better pick, even in the case of path models. Let's try it out and compare the results.

#### Selecting priors

I already scaled all variables of interest. This will make it a bit simpler to select priors. I will use weakly informative priors for slope and intercept parameters again (see <https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations>). I do this merely to keep things simple and straightforward here - usually a few more thoughts should be placed in specifying your prior. The selected prior is $N(0,1)$. Let's plot to prior to see what kind of an effect it may have on our parameters.

```{r plt-priors, message=FALSE, warning=FALSE}

colors <- ipsum_pal()(1)

prior(normal(0, 1)) %>% 
  parse_dist() %>% 
  
  ggplot(aes(xdist = .dist_obj, y = prior)) + 
  stat_halfeye(.width = 0.683, p_limits = c(.001, .999), 
               slab_fill = colors[1], slab_alpha = 0.8) +
  scale_y_discrete(NULL, breaks = NULL, expand = expansion(add = 0.1)) +
  labs(title = "Prior N(0,1)", x = "Parameter Space", y = "") +
  coord_cartesian(xlim = c(-4, 4)) +
  scale_x_continuous(breaks = seq(-4, 4, by = 1)) +
  theme_ipsum() +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) 
```

#### Setting up the model

In brms we have to specify our model a bit different than previously. However, in principle, we are doing nothing else than fitting a multivariate linear regression once again. The way we set up this model should thus remind both of what we specified in the previous blog post, and of the lavaan syntax from above.

```{r brms-indirect-association-model}

model2 <- 
  # direct and indirect paths to ideological factors
  bf(conservatism_factor ~ Age + SpeededIP + StrategicIP + Percep + Caution + Discount) + 
  bf(dogmatism_factor ~ Age + SpeededIP + StrategicIP + Percep + Caution + Discount) + 
  bf(religiosity_factor ~ Age + SpeededIP + StrategicIP + Percep + Caution + Discount) +
  # paths from age to indirect predictors (cognitive factors)
  bf(SpeededIP ~ Age) + 
  bf(StrategicIP ~ Age) + 
  bf(Percep ~ Age) + 
  bf(Caution ~ Age) + 
  bf(Discount ~ Age)
```

Let's check how our priors are set by default in `brms`.

```{r check-default-priors}
get_prior(model2 + set_rescor(FALSE), data = df)
```

By default `brms` sets non-informative flat priors for our slope parameters. We thus have to change this, and can do so directly when fitting the model.

#### Fitting and summarising the first model

```{r model3-fitting}
m3 <- brm(model2 + set_rescor(FALSE), 
          data = df, 
          prior = c(prior(normal(0, 1), class = "Intercept"), 
                    prior(normal(0, 1), class = "b")),
          seed = bayes_seed,
          file = "02_fits/fit_m3")
```

We get a warning message:

```         
Warning: Rows containing NAs were excluded from the model.
```

We are not happy with this, but for now we will deal with it later.

Check the results. As usual, we can also use `summary(m1.1)` or `print(m1.1)` to do so.

```{r model1.1-results}
summary(m3, prob = 0.95)  # prob = 0.95 is the default
```

This time, we need some trickery to compute the indirect effects. Let's remind ourselves how we did this previously - what I write out below, is what we specified in the lavaan syntax.

The indirect effect in general is calculated by the multiplication of the path from the direct predictor to the indirect predictor (a)

-   In this case, this is the path from Age to SpeededIP, StrategicIP, Percep, Caution, Discount respectively

with the path from the indirect predictor to the outcome (b)

-   In this case, this is the path from SpeededIP, StrategicIP, Percep, Caution, Discount to conservatism_factor, dogmatism_factor, or religiosity_factor

And the direct paths (c) are the paths from the direct predictor to the outcome

-   In this case, this is the path from Age to conservatism_factor, dogmatism_factor, or religiosity_factor

The overall indirect effect for one outcome is nothing but the sum of all indirect effects to that outcome.

The total effects are nothing but the sum of the indirect and direct effects.

In brms we get the posterior of all of those effects. We can use the posterior draws to calculate these effects - though some manual work is needed. Let's first extract the draws.

```{r m3-wdraws}
m3_draws <- as_draws_df(m3)
head(m3_draws)
```

Now let's try to calculate the indirect effects.

```{r}
m3_draws <- m3_draws %>% 
  mutate(
    # Age -> Conservatism
    ind_Age_Spe_Con = b_SpeededIP_Age * b_conservatismfactor_SpeededIP,
    ind_Age_Str_Con = b_StrategicIP_Age * b_conservatismfactor_StrategicIP,
    ind_Age_Per_Con = b_Percep_Age * b_conservatismfactor_Percep,
    ind_Age_Cau_Con = b_Caution_Age * b_conservatismfactor_Caution,
    ind_Age_Dis_Con = b_Discount_Age * b_conservatismfactor_Discount,
    ind_Age_Con = ind_Age_Spe_Con + ind_Age_Str_Con + ind_Age_Per_Con + ind_Age_Cau_Con + ind_Age_Dis_Con,
    tot_Age_Con = ind_Age_Con + b_conservatismfactor_Age,
    
    # Age -> Dogmatism
    ind_Age_Spe_Dog = b_SpeededIP_Age * b_dogmatismfactor_SpeededIP,
    ind_Age_Str_Dog = b_StrategicIP_Age * b_dogmatismfactor_StrategicIP,
    ind_Age_Per_Dog = b_Percep_Age * b_dogmatismfactor_Percep,
    ind_Age_Cau_Dog = b_Caution_Age * b_dogmatismfactor_Caution,
    ind_Age_Dis_Dog = b_Discount_Age * b_dogmatismfactor_Discount,
    ind_Age_Dog = ind_Age_Spe_Dog + ind_Age_Str_Dog + ind_Age_Per_Dog + ind_Age_Cau_Dog + ind_Age_Dis_Dog,
    tot_Age_Dog = ind_Age_Dog + b_dogmatismfactor_Age,
    
    # Age -> Religiosity
    ind_Age_Spe_Rel = b_SpeededIP_Age * b_religiosityfactor_SpeededIP,
    ind_Age_Str_Rel = b_StrategicIP_Age * b_religiosityfactor_StrategicIP,
    ind_Age_Per_Rel = b_Percep_Age * b_religiosityfactor_Percep,
    ind_Age_Cau_Rel = b_Caution_Age * b_religiosityfactor_Caution,
    ind_Age_Dis_Rel = b_Discount_Age * b_religiosityfactor_Discount,
    ind_Age_Rel = ind_Age_Spe_Rel + ind_Age_Str_Rel + ind_Age_Per_Rel + ind_Age_Cau_Rel + ind_Age_Dis_Rel,
    tot_Age_Rel = ind_Age_Rel + b_religiosityfactor_Age
    )
```

Use the `describe_posterior` function to get some summary statistics of what we calculated.

```{r}
m3_draws %>% 
  select(45:65) %>% 
  describe_posterior(., 
                     centrality = "median",
                     dispersion = FALSE,
                     ci = 0.95,
                     ci_method = "hdi",
                     rope_range = c(-0.02, 0.02),
                     rope_ci = 1) 
```

Alrighty, let's compare to what we obtained previously in lavaan

```{r}
parest1 %>% 
  slice(55:75) %>% 
  select(label, est, pvalue, ci.lower, ci.upper) %>% 
  mutate(across(where(is.numeric), ~round(.x, 2))) %>% 
  tt(.)
```

The results that we got are very very similar and lead to the same interpretation.

However, before we interpret the estimates at all, it is best practice to check if our model converged properly. Let's follow the steps of the WAMB checklist this time!

## Resources

I am not a statistician, so please take all of what I wrote and coded here with a lot of caution. However, there are many great resources out there if you want to delve deeper into the topic - I am just getting started with this, but here are a few potentially helpful links.

-   [*Doing Bayesian Data Analysis* in brms and the tidyverse](https://bookdown.org/content/3686/): A brms and tidyverse version by Solomon Kurz of the classic book by Kruschke [*Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan*](https://sites.google.com/site/doingbayesiandataanalysis/). 

-   [Practical Bayes Part I](https://m-clark.github.io/posts/2021-02-28-practical-bayes-part-i/#rhat-effective-sample-size) and [Practical Bayes Part II](https://m-clark.github.io/posts/2021-02-28-practical-bayes-part-ii/): Great resources to dealing and avoiding common problems in Bayesian models by Micheal Clark

-   [Bayesian Basics](https://m-clark.github.io/bayesian-basics/preface.html): General overview of how to run Bayesian models in R

-   [bayestestR](https://easystats.github.io/bayestestR/index.html): Vignettes on basic Bayesian models and their interpretation

-   [Stan Wiki: Prior Choice](https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations): Go to reference for selecting priors

-   [Course Handouts for Bayesian Data Analysis Class](https://bookdown.org/marklhc/notes_bookdown/) by Mark Lai

And there are of course many many more resources, this is just to get started with some.
